{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_2e12b3",
   "metadata": {},
   "source": "# Bloque 2.3 ‚Äî M√©tricas de Evaluaci√≥n de Clustering\n**M√°ster en Ciencia de Datos ¬∑ M√≥dulo: Algoritmos de Clustering**\n**Sesi√≥n 2 ¬∑ Duraci√≥n: 65 min**\n\n---\n> üìå **C√≥mo usar este notebook:**\n> Ejecuta las celdas **en orden**. Cada secci√≥n comienza con explicaci√≥n te√≥rica (en Markdown) seguida del c√≥digo correspondiente.\n> Los comentarios `# ---` delimitan ejercicios opcionales para profundizar.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_02c4cc",
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.metrics import adjusted_rand_score\nari = adjusted_rand_score(labels_verdaderos, labels_predichos)"
  },
  {
   "cell_type": "markdown",
   "id": "md_ef3cd2",
   "metadata": {},
   "source": "**Ventaja:** invariante a permutaciones de etiquetas (el cluster 0 predicho puede corresponder al cluster 2 real). Ajustado por el azar.\n\n#### Normalized Mutual Information (NMI)\n\nMide la informaci√≥n mutua entre las dos particiones, normalizada para que est√© en [0, 1]. 1 = particiones id√©nticas, 0 = completamente independientes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_17590e",
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.metrics import normalized_mutual_info_score\nnmi = normalized_mutual_info_score(labels_verdaderos, labels_predichos)"
  },
  {
   "cell_type": "markdown",
   "id": "md_403066",
   "metadata": {},
   "source": "#### V-Measure (completeness + homogeneity)\n\nCombina dos m√©tricas:\n- **Homogeneidad:** cada cluster contiene solo puntos de una clase real.\n- **Completeness:** todos los puntos de una clase est√°n en el mismo cluster.\n- **V-Measure:** media harm√≥nica de ambas.\n\n---\n\n### [00:20 ‚Äì 00:25] Reglas de uso y las trampas de las m√©tricas\n\n*\"Antes de la pr√°ctica, quiero que teng√°is en mente cuatro advertencias sobre las m√©tricas de clustering. Son las m√°s olvidadas en proyectos reales.\"*\n\n**Trampa 1 ‚Äî El mejor Silhouette no siempre es la mejor soluci√≥n:**\nSilhouette maximiza la separaci√≥n entre clusters. A veces la soluci√≥n con mayor Silhouette tiene clusters artificialmente peque√±os que no tienen sentido de negocio. **Regla:** las m√©tricas gu√≠an, no deciden.\n\n**Trampa 2 ‚Äî CHI favorece clusters esf√©ricos:**\nCalinski-Harabasz dar√° valores altos para K-Means aunque DBSCAN capture mejor la estructura real. Usad CHI solo para comparar el mismo algoritmo con distintos K, no para comparar algoritmos distintos.\n\n**Trampa 3 ‚Äî Las m√©tricas no capturan interpretabilidad:**\nUn clustering con Silhouette 0.9 pero cuyos clusters son imposibles de nombrar o actuar tiene menos valor que uno con Silhouette 0.5 pero con segmentos claros y accionables.\n\n**Trampa 4 ‚Äî Nunca usar una sola m√©trica:**\nLa pr√°ctica correcta es triangular: Silhouette + DBI + CHI + inspecci√≥n visual + juicio de negocio. Si tres m√©tricas convergen en el mismo K, es un resultado robusto.\n\n---\n\n## PARTE PR√ÅCTICA ‚Äî Jupyter Notebook (40 min)\n\n---\n\n### [00:25 ‚Äì 01:05] Pr√°ctica guiada\n\n---\n\n#### Celda 1 ‚Äî Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_3a9f92",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BLOQUE 2.3 ‚Äî M√©tricas de Evaluaci√≥n de Clustering\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nimport seaborn as sns\n\nfrom sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_blobs, make_moons\nfrom sklearn.metrics import (\n    silhouette_score, silhouette_samples,\n    davies_bouldin_score,\n    calinski_harabasz_score,\n    adjusted_rand_score,\n    normalized_mutual_info_score\n)\n\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 12\nsns.set_style(\"whitegrid\")\nnp.random.seed(42)\n\nprint(\"‚úì Imports correctos\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_70d0fd",
   "metadata": {},
   "source": "---\n\n#### Celda 2 ‚Äî Silhouette plot: la m√©trica en detalle"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_d8e27a",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# Silhouette plot: an√°lisis punto a punto\n# -------------------------------------------------------\n\nX_blob, y_real = make_blobs(n_samples=300, centers=4,\n                             cluster_std=0.9, random_state=5)\nX_blob_norm = StandardScaler().fit_transform(X_blob)\n\nfig, axes = plt.subplots(2, 3, figsize=(17, 11))\naxes = axes.flatten()\n\nfor idx, k in enumerate([2, 3, 4, 5, 6, 7]):\n    ax = axes[idx]\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n    labels = km.fit_predict(X_blob_norm)\n\n    sil_avg  = silhouette_score(X_blob_norm, labels)\n    sil_vals = silhouette_samples(X_blob_norm, labels)\n\n    colores = cm.nipy_spectral(np.linspace(0.1, 0.9, k))\n    y_lower = 10\n\n    for c in range(k):\n        c_vals = np.sort(sil_vals[labels == c])\n        y_upper = y_lower + len(c_vals)\n        ax.fill_betweenx(np.arange(y_lower, y_upper), 0, c_vals,\n                         facecolor=colores[c], edgecolor=colores[c], alpha=0.7)\n        ax.text(-0.05, y_lower + 0.5 * len(c_vals), str(c), fontsize=8)\n        y_lower = y_upper + 5\n\n    ax.axvline(x=sil_avg, color='red', linestyle='--', linewidth=1.5)\n    ax.set_title(f\"k={k} ‚Äî Silhouette avg = {sil_avg:.3f}\", fontsize=10, fontweight='bold')\n    ax.set_xlabel(\"Coeficiente Silhouette\")\n    ax.set_ylabel(\"Cluster\")\n    ax.set_xlim([-0.2, 1])\n    ax.set_yticks([])\n\nplt.suptitle(\"Silhouette plots para k=2..7 ‚Äî Dataset blobs (4 clusters reales)\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_silhouette_plots.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"Interpretaci√≥n del Silhouette plot:\")\nprint(\"  Cada barra horizontal = un punto. Anchura = valor silhouette.\")\nprint(\"  Barras que cruzan la l√≠nea roja (media) hacia la izquierda ‚Üí puntos problem√°ticos.\")\nprint(\"  Barras de anchura uniforme ‚Üí cluster compacto y bien separado.\")\nprint(\"  k=4 deber√≠a tener los plots m√°s uniformes (es el k real).\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_09432d",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"El silhouette plot es la visualizaci√≥n m√°s informativa de todas las m√©tricas. Cada barra es un punto. Si las barras de un cluster son cortas ‚Äîno llegan a la l√≠nea roja‚Äî ese cluster tiene puntos mal asignados. Si son todas largas y uniformes, el cluster es compacto y bien separado. Comparad k=2 con k=4: en k=4 los plots son mucho m√°s limpios porque coincide con la estructura real.\"*\n\n---\n\n#### Celda 3 ‚Äî Comparaci√≥n de las tres m√©tricas para distintos K"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_e197a3",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# Las tres m√©tricas juntas para elegir K √≥ptimo\n# -------------------------------------------------------\n\nks = range(2, 11)\nresultados = {'k': list(ks), 'silhouette': [], 'davies_bouldin': [], 'calinski_harabasz': []}\n\nfor k in ks:\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n    labels = km.fit_predict(X_blob_norm)\n    resultados['silhouette'].append(silhouette_score(X_blob_norm, labels))\n    resultados['davies_bouldin'].append(davies_bouldin_score(X_blob_norm, labels))\n    resultados['calinski_harabasz'].append(calinski_harabasz_score(X_blob_norm, labels))\n\ndf_metricas = pd.DataFrame(resultados).set_index('k')\n\n# Normalizar para comparaci√≥n visual en [0,1]\ndf_norm = df_metricas.copy()\ndf_norm['silhouette_norm']      = (df_metricas['silhouette'] - df_metricas['silhouette'].min()) / \\\n                                   (df_metricas['silhouette'].max() - df_metricas['silhouette'].min())\ndf_norm['dbi_norm_inv']         = 1 - (df_metricas['davies_bouldin'] - df_metricas['davies_bouldin'].min()) / \\\n                                       (df_metricas['davies_bouldin'].max() - df_metricas['davies_bouldin'].min())\ndf_norm['chi_norm']             = (df_metricas['calinski_harabasz'] - df_metricas['calinski_harabasz'].min()) / \\\n                                   (df_metricas['calinski_harabasz'].max() - df_metricas['calinski_harabasz'].min())\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# M√©tricas en escala original\nax1 = axes[0]\nax1.plot(ks, df_metricas['silhouette'], 'bo-', linewidth=2, label='Silhouette ‚Üë')\nax1b = ax1.twinx()\nax1b.plot(ks, df_metricas['davies_bouldin'], 'r^--', linewidth=2, label='Davies-Bouldin ‚Üì')\nax1.set_xlabel(\"N√∫mero de clusters (k)\")\nax1.set_ylabel(\"Silhouette Score\", color='blue')\nax1b.set_ylabel(\"Davies-Bouldin Index\", color='red')\nax1.set_title(\"Silhouette y Davies-Bouldin\\nvs. n√∫mero de clusters\",\n              fontsize=11, fontweight='bold')\nax1.set_xticks(ks)\nlines1, labs1 = ax1.get_legend_handles_labels()\nlines2, labs2 = ax1b.get_legend_handles_labels()\nax1.legend(lines1 + lines2, labs1 + labs2, fontsize=9)\n\n# M√©tricas normalizadas juntas\nax2 = axes[1]\nax2.plot(ks, df_norm['silhouette_norm'], 'bo-', linewidth=2, markersize=7,\n         label='Silhouette (normalizado) ‚Üë')\nax2.plot(ks, df_norm['dbi_norm_inv'], 'r^--', linewidth=2, markersize=7,\n         label='1 - DBI (normalizado) ‚Üë')\nax2.plot(ks, df_norm['chi_norm'], 'gs-.', linewidth=2, markersize=7,\n         label='Calinski-Harabasz (normalizado) ‚Üë')\nax2.axvline(x=4, color='black', linestyle=':', linewidth=2, label='k real = 4')\nax2.set_xlabel(\"N√∫mero de clusters (k)\")\nax2.set_ylabel(\"Puntuaci√≥n normalizada [0,1] (mayor = mejor)\")\nax2.set_title(\"Las tres m√©tricas normalizadas juntas\\n(coinciden en k=4 ‚Üí resultado robusto)\",\n              fontsize=11, fontweight='bold')\nax2.legend(fontsize=8)\nax2.set_xticks(ks)\n\nplt.suptitle(\"Triangulaci√≥n de m√©tricas para seleccionar k √≥ptimo\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_metricas_triangulacion.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nk_optimos = {\n    'Silhouette':          df_metricas['silhouette'].idxmax(),\n    'Davies-Bouldin':      df_metricas['davies_bouldin'].idxmin(),\n    'Calinski-Harabasz':   df_metricas['calinski_harabasz'].idxmax(),\n}\nprint(\"K √≥ptimo seg√∫n cada m√©trica:\")\nfor metrica, k_opt in k_optimos.items():\n    print(f\"  {metrica}: k={k_opt}\")\nprint(f\"\\n‚Üí Las tres coinciden en k={pd.Series(k_optimos).mode()[0]} ‚úì\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_fe1a65",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Este es el patr√≥n que quer√©is ver: las tres m√©tricas apuntando al mismo k. Cuando las tres coinciden, el resultado es robusto ‚Äîno es un artefacto de una sola m√©trica. En este caso las tres se√±alan k=4, que es exactamente el k real que usamos para generar los datos.\"*\n\n*\"En datos reales, las tres rara vez coinciden exactamente. Pero os dan un rango plausible de k values. Luego vuestro juicio de negocio decide cu√°ntos segmentos son accionables.\"*\n\n---\n\n#### Celda 4 ‚Äî Comparaci√≥n de algoritmos con las mismas m√©tricas"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_01cfc7",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# ¬øQu√© algoritmo da mejores clusters para este dataset?\n# Usando las m√©tricas como √°rbitro objetivo\n# -------------------------------------------------------\n\n# Dataset: blobs est√°ndar (caso favorable para K-Means)\nX_eval, y_eval = make_blobs(n_samples=400, centers=4,\n                             cluster_std=0.85, random_state=7)\nX_eval_norm = StandardScaler().fit_transform(X_eval)\n\nalgoritmos = {\n    'K-Means k=4': KMeans(n_clusters=4, n_init=10, random_state=42),\n    'GMM k=4':     GaussianMixture(n_components=4, n_init=5, random_state=42),\n    'Jer√°rquico Ward k=4': AgglomerativeClustering(n_clusters=4, linkage='ward'),\n}\n\nfilas = []\nfor nombre, modelo in algoritmos.items():\n    if isinstance(modelo, GaussianMixture):\n        modelo.fit(X_eval_norm)\n        labels = modelo.predict(X_eval_norm)\n    else:\n        labels = modelo.fit_predict(X_eval_norm)\n\n    sil = silhouette_score(X_eval_norm, labels)\n    dbi = davies_bouldin_score(X_eval_norm, labels)\n    chi = calinski_harabasz_score(X_eval_norm, labels)\n    ari = adjusted_rand_score(y_eval, labels)\n    filas.append({'Algoritmo': nombre, 'Silhouette ‚Üë': sil,\n                  'Davies-Bouldin ‚Üì': dbi, 'Calinski-Harabasz ‚Üë': chi,\n                  'ARI (vs. real) ‚Üë': ari})\n\ndf_comp = pd.DataFrame(filas).set_index('Algoritmo')\nprint(\"Comparaci√≥n de algoritmos ‚Äî Dataset blobs (4 clusters reales):\")\nprint(df_comp.round(4).to_string())\n\nprint(\"\\n‚Üí En datos convexos, los tres algoritmos dan resultados muy similares.\")\nprint(\"  El ARI confirma que los tres recuperan bien la estructura real.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_743439",
   "metadata": {},
   "source": "---\n\n#### Celda 5 ‚Äî Dashboard de evaluaci√≥n: selecci√≥n autom√°tica del mejor K"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_892c13",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# EJERCICIO INTEGRADOR:\n# dado un dataset desconocido, elegir autom√°ticamente\n# el mejor algoritmo y el mejor K\n# -------------------------------------------------------\n\ndef evaluar_clustering(X, k_min=2, k_max=8, algoritmos_k=['kmeans'],\n                       verbose=True):\n    \"\"\"\n    Eval√∫a autom√°ticamente m√∫ltiples configuraciones de clustering.\n    Devuelve un DataFrame con todas las m√©tricas y recomienda la mejor.\n    \"\"\"\n    resultados = []\n\n    for k in range(k_min, k_max + 1):\n        for algo in algoritmos_k:\n            if algo == 'kmeans':\n                modelo = KMeans(n_clusters=k, n_init=10, random_state=42)\n                labels = modelo.fit_predict(X)\n                nombre = f'K-Means k={k}'\n            elif algo == 'gmm':\n                modelo = GaussianMixture(n_components=k, n_init=5, random_state=42)\n                modelo.fit(X)\n                labels = modelo.predict(X)\n                nombre = f'GMM k={k}'\n            elif algo == 'ward':\n                modelo = AgglomerativeClustering(n_clusters=k, linkage='ward')\n                labels = modelo.fit_predict(X)\n                nombre = f'Ward k={k}'\n\n            # Saltar si solo hay un cluster real\n            if len(np.unique(labels)) < 2:\n                continue\n\n            sil = silhouette_score(X, labels)\n            dbi = davies_bouldin_score(X, labels)\n            chi = calinski_harabasz_score(X, labels)\n\n            resultados.append({\n                'Configuraci√≥n': nombre, 'k': k,\n                'Silhouette ‚Üë': round(sil, 4),\n                'DBI ‚Üì': round(dbi, 4),\n                'CHI ‚Üë': round(chi, 1),\n            })\n\n    df_res = pd.DataFrame(resultados)\n\n    # Puntuaci√≥n compuesta (normalizada, las tres m√©tricas con igual peso)\n    df_res['sil_norm'] = (df_res['Silhouette ‚Üë'] - df_res['Silhouette ‚Üë'].min()) / \\\n                          (df_res['Silhouette ‚Üë'].max() - df_res['Silhouette ‚Üë'].min() + 1e-9)\n    df_res['dbi_norm'] = 1 - (df_res['DBI ‚Üì'] - df_res['DBI ‚Üì'].min()) / \\\n                              (df_res['DBI ‚Üì'].max() - df_res['DBI ‚Üì'].min() + 1e-9)\n    df_res['chi_norm'] = (df_res['CHI ‚Üë'] - df_res['CHI ‚Üë'].min()) / \\\n                          (df_res['CHI ‚Üë'].max() - df_res['CHI ‚Üë'].min() + 1e-9)\n    df_res['Score compuesto'] = (df_res['sil_norm'] + df_res['dbi_norm'] + df_res['chi_norm']) / 3\n\n    df_res_clean = df_res.drop(columns=['k','sil_norm','dbi_norm','chi_norm'])\n\n    if verbose:\n        print(df_res_clean.sort_values('Score compuesto', ascending=False)\n              .head(5).to_string(index=False))\n        mejor = df_res_clean.loc[df_res['Score compuesto'].idxmax(), 'Configuraci√≥n']\n        print(f\"\\n‚Üí Configuraci√≥n recomendada: '{mejor}'\")\n\n    return df_res_clean.sort_values('Score compuesto', ascending=False)\n\n\n# Probamos con el dataset de Mall Customers\nprint(\"=== Dashboard de evaluaci√≥n autom√°tica ===\\n\")\nnp.random.seed(0)\nn = 200\ndf_mall_eval = pd.DataFrame({\n    'Annual_Income_k': np.concatenate([\n        np.random.normal(20,5,30), np.random.normal(20,5,30),\n        np.random.normal(55,8,40), np.random.normal(85,7,50), np.random.normal(85,7,50)\n    ]),\n    'Spending_Score': np.concatenate([\n        np.random.normal(20,6,30), np.random.normal(80,6,30),\n        np.random.normal(50,8,40), np.random.normal(15,6,50), np.random.normal(82,6,50)\n    ])\n}).clip(lower=0)\nX_mall_eval = StandardScaler().fit_transform(df_mall_eval)\n\ndf_resultados = evaluar_clustering(\n    X_mall_eval, k_min=2, k_max=8,\n    algoritmos_k=['kmeans', 'gmm', 'ward']\n)"
  },
  {
   "cell_type": "markdown",
   "id": "md_7635e6",
   "metadata": {},
   "source": "---\n\n#### Celda 6 ‚Äî Las trampas de las m√©tricas: cuando el mejor score no es la mejor soluci√≥n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_a174f8",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# DEMOSTRACI√ìN: Silhouette puede mentir\n# -------------------------------------------------------\n\nprint(\"=== Caso donde Silhouette puede ser enga√±oso ===\\n\")\n\n# Dataset: lunas (estructura no convexa)\nX_lunas, y_lunas = make_moons(n_samples=300, noise=0.06, random_state=42)\nX_lunas_norm = StandardScaler().fit_transform(X_lunas)\n\nresultados_lunas = []\nfor k in range(2, 7):\n    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n    labels_km = km.fit_predict(X_lunas_norm)\n    sil = silhouette_score(X_lunas_norm, labels_km)\n    resultados_lunas.append({'k': k, 'Silhouette K-Means': round(sil, 4)})\n\n# DBSCAN (el correcto para este dataset)\ndb = DBSCAN(eps=0.18, min_samples=5)\nlabels_db = db.fit_predict(X_lunas_norm)\nmask_no_noise = labels_db != -1\nsil_db = silhouette_score(X_lunas_norm[mask_no_noise], labels_db[mask_no_noise])\nari_db = adjusted_rand_score(y_lunas[mask_no_noise], labels_db[mask_no_noise])\n\nprint(\"K-Means en dataset de lunas:\")\ndf_lunas = pd.DataFrame(resultados_lunas).set_index('k')\nprint(df_lunas)\nprint(f\"\\nDBSCAN (correcto para este dataset):\")\nprint(f\"  Silhouette: {sil_db:.4f}\")\nprint(f\"  ARI vs. etiquetas reales: {ari_db:.4f}\")\n\nprint(f\"\"\"\nAn√°lisis:\n  K-Means con k=2 puede tener un Silhouette {'mayor' if resultados_lunas[0]['Silhouette K-Means'] > sil_db else 'menor'} que DBSCAN.\n  Sin embargo, DBSCAN recupera la estructura real (ARI={ari_db:.2f} ‚âà 1.0).\n\n  Conclusi√≥n: Silhouette mide separaci√≥n convexa.\n  En clusters no convexos, un Silhouette alto puede ser un artefacto.\n  Usad siempre la m√©trica junto con la INSPECCI√ìN VISUAL.\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_12dd11",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Este ejemplo es importante. K-Means partiendo las lunas puede tener un Silhouette comparable o incluso mayor que DBSCAN, porque Silhouette mide separaci√≥n lineal. Pero el ARI contra las etiquetas reales revela que DBSCAN es mucho mejor. Moraleja: las m√©tricas internas son herramientas, no √°rbitros absolutos. Siempre combinadlas con visualizaci√≥n.\"*\n\n---\n\n#### Celda 7 ‚Äî Tabla final de referencia"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_bc6039",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 70)\nprint(\"GU√çA DE REFERENCIA ‚Äî M√âTRICAS DE EVALUACI√ìN DE CLUSTERING\")\nprint(\"=\" * 70)\n\ntabla_ref = pd.DataFrame({\n    'M√©trica': ['Silhouette', 'Davies-Bouldin', 'Calinski-Harabasz', 'ARI', 'NMI'],\n    'Rango': ['[-1, 1]', '[0, ‚àû)', '[0, ‚àû)', '[-1, 1]', '[0, 1]'],\n    'Mejor': ['‚Üë Mayor', '‚Üì Menor', '‚Üë Mayor', '‚Üë Mayor', '‚Üë Mayor'],\n    'Necesita GT': ['No', 'No', 'No', 'S√≠', 'S√≠'],\n    'Complejidad': ['O(n¬≤)', 'O(n¬∑K)', 'O(n¬∑K)', 'O(n)', 'O(n)'],\n    'Limitaci√≥n principal': [\n        'Asume convexidad',\n        'Solo centroides',\n        'Asume convexidad',\n        'Requiere ground truth',\n        'Requiere ground truth',\n    ]\n}).set_index('M√©trica')\n\nprint(tabla_ref.to_string())\nprint(\"\"\"\nProtocolo de evaluaci√≥n recomendado:\n  1. Silhouette plot ‚Üí analizar cluster por cluster\n  2. DBI + CHI ‚Üí confirmar con m√©tricas m√°s r√°pidas\n  3. Inspecci√≥n visual ‚Üí siempre obligatoria\n  4. Juicio de negocio ‚Üí ¬ølos clusters son accionables?\n  5. ARI/NMI ‚Üí solo si se dispone de ground truth\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_394460",
   "metadata": {},
   "source": "---\n\n## NOTAS DE PRODUCCI√ìN\n\n### Para las slides\n\n- **Slide 1:** Portada. La pregunta: *\"¬øC√≥mo s√© si mis clusters son buenos?\"*\n- **Slide 2:** M√©tricas internas vs. externas ‚Äî diagrama comparativo.\n- **Slide 3:** Silhouette ‚Äî f√≥rmula de `a(i)`, `b(i)`, `s(i)` con diagrama geom√©trico.\n- **Slide 4:** Davies-Bouldin ‚Äî f√≥rmula y diagrama de compacidad vs. separaci√≥n.\n- **Slide 5:** Calinski-Harabasz ‚Äî SS_between vs. SS_within visualmente.\n- **Slide 6:** Las cuatro advertencias sobre m√©tricas ‚Äî tarjetas de advertencia.\n- **Slide 7:** El protocolo de evaluaci√≥n en 5 pasos.\n\n### Para el handout\n\n- Tabla de referencia completa de m√©tricas (Celda 7).\n- Silhouette plots para k=3 y k=4 lado a lado (Celda 2) con gu√≠a de lectura.\n- Gr√°fico de triangulaci√≥n de m√©tricas (Celda 3).\n- La demostraci√≥n de Silhouette enga√±oso (Celda 6) como caso de advertencia.\n- El protocolo de evaluaci√≥n en 5 pasos.\n\n### Para el Jupyter Notebook (ejercicios a completar)\n\n**Ejercicio 1:** Aplicar el dashboard de evaluaci√≥n (`evaluar_clustering`) al dataset de pa√≠ses del Bloque 1.3. ¬øEl k recomendado coincide con el que elegisteis visualmente por el dendrograma?\n\n**Ejercicio 2:** Calcular el Silhouette plot para K-Medoids con k=5 en el dataset Mall Customers. ¬øLos clusters tienen Silhouette m√°s uniforme que K-Means?\n\n**Ejercicio 3 (avanzado):** Implementar el c√°lculo del Silhouette Score desde cero usando NumPy y scipy.spatial.distance. Verificar que coincide con `sklearn.metrics.silhouette_score`.\n\n---\n\n## GESTI√ìN DEL TIEMPO\n\n| Segmento | Duraci√≥n | Indicador |\n|---|---|---|\n| Transici√≥n + distinci√≥n interna/externa | 4 min | Diagrama en pantalla |\n| Silhouette (f√≥rmula + interpretaci√≥n) | 5 min | F√≥rmulas en pantalla |\n| Davies-Bouldin + Calinski-Harabasz | 4 min | Tabla comparativa en pantalla |\n| M√©tricas externas (ARI, NMI) | 3 min | F√≥rmulas en pantalla |\n| Las cuatro trampas | 4 min | Tarjetas en pantalla |\n| Protocolo de 5 pasos | 5 min | Lista en pantalla |\n| Celda 1-2 (imports + Silhouette plots) | 10 min | 6 plots generados |\n| Celda 3 (triangulaci√≥n) | 8 min | Gr√°fico de m√©tricas generado |\n| Celda 4 (comparaci√≥n algoritmos) | 7 min | Tabla impresa |\n| Celda 5 (dashboard autom√°tico) | 8 min | Top 5 configuraciones |\n| Celda 6-7 (trampa + tabla final) | 7 min | Demostraci√≥n enga√±o + tabla |\n| **Total** | **65 min** | |\n\n---\n\n*Bloque 2.3 desarrollado para el m√≥dulo \"Algoritmos de Clustering\" ‚Äî M√°ster en Ciencia de Datos*"
  },
  {
   "cell_type": "markdown",
   "id": "md_032132",
   "metadata": {},
   "source": "---\n## üí° Para explorar m√°s ‚Äî Ejercicios propuestos\n\nLos ejercicios pr√°cticos est√°n marcados con comentarios `# EJERCICIO` en el c√≥digo.\n\n**Entrega sugerida:** Exporta este notebook como HTML o PDF (`File ‚Üí Download ‚Üí HTML`)\ny a√±ade tus conclusiones en una celda Markdown al final de cada secci√≥n.\n\n---\n*M√°ster en Ciencia de Datos ¬∑ M√≥dulo Clustering ¬∑ Bloque 2.3*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}