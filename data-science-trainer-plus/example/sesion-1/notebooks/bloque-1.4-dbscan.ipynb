{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_50ff9a",
   "metadata": {},
   "source": "# Bloque 1.4 ‚Äî DBSCAN\n**M√°ster en Ciencia de Datos ¬∑ M√≥dulo: Algoritmos de Clustering**\n**Sesi√≥n 1 ¬∑ Duraci√≥n: 60 min**\n\n---\n> üìå **C√≥mo usar este notebook:**\n> Ejecuta las celdas **en orden**. Cada secci√≥n comienza con explicaci√≥n te√≥rica (en Markdown) seguida del c√≥digo correspondiente.\n> Los comentarios `# ---` delimitan ejercicios opcionales para profundizar.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_23f721",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BLOQUE 1.4 ‚Äî DBSCAN: Clustering Basado en Densidad\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport seaborn as sns\n\nfrom sklearn.cluster import DBSCAN, KMeans\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_moons, make_circles, make_blobs\nfrom sklearn.neighbors import NearestNeighbors\n\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 12\nsns.set_style(\"whitegrid\")\nnp.random.seed(42)\n\nprint(\"‚úì Imports correctos\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_be968f",
   "metadata": {},
   "source": "---\n\n#### Celda 2 ‚Äî Demostraci√≥n visual de los tres tipos de puntos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_a71343",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# Visualizaci√≥n pedag√≥gica: n√∫cleo, frontera, ruido\n# con un dataset m√≠nimo y Œµ visible\n# -------------------------------------------------------\n\nnp.random.seed(1)\n\n# Dataset peque√±o con estructura clara para demostraci√≥n\nX_demo = np.array([\n    # Regi√≥n densa izquierda (cluster 1)\n    [1.0, 2.0], [1.3, 2.1], [0.9, 1.8], [1.1, 2.3], [1.4, 1.9],\n    [0.8, 2.2], [1.2, 1.7], [1.5, 2.4],\n    # Regi√≥n densa derecha (cluster 2)\n    [5.0, 2.0], [5.2, 2.1], [4.8, 1.9], [5.1, 2.3], [4.9, 1.8],\n    # Punto frontera entre clusters (no llega a ser n√∫cleo)\n    [3.0, 2.0],\n    # Outliers aislados\n    [0.0, 5.0], [6.5, 0.5],\n])\n\neps    = 0.8\nminpts = 3\n\n# Calculamos tipo de cada punto manualmente para ilustraci√≥n\nfrom sklearn.neighbors import NearestNeighbors\n\nnbrs = NearestNeighbors(radius=eps).fit(X_demo)\nvecindades = nbrs.radius_neighbors(X_demo, return_distance=False)\nn_vecinos  = np.array([len(v) for v in vecindades])  # incluye el propio punto\n\nes_nucleo   = n_vecinos >= minpts\nes_ruido    = np.zeros(len(X_demo), dtype=bool)\nes_frontera = np.zeros(len(X_demo), dtype=bool)\n\n# Un punto es frontera si no es n√∫cleo pero est√° en la vecindad de un n√∫cleo\nfor i, vecinos in enumerate(vecindades):\n    if not es_nucleo[i]:\n        if any(es_nucleo[v] for v in vecinos if v != i):\n            es_frontera[i] = True\n        else:\n            es_ruido[i] = True\n\n# Visualizaci√≥n\nfig, ax = plt.subplots(figsize=(10, 7))\n\n# C√≠rculos Œµ alrededor de los puntos n√∫cleo (muestra solo algunos)\nfor i in np.where(es_nucleo)[0][:4]:\n    circulo = plt.Circle(X_demo[i], eps, color='steelblue',\n                         fill=True, alpha=0.08, linestyle='--', linewidth=1)\n    ax.add_patch(circulo)\n    circulo_borde = plt.Circle(X_demo[i], eps, color='steelblue',\n                               fill=False, linestyle='--', linewidth=1)\n    ax.add_patch(circulo_borde)\n\n# Puntos coloreados por tipo\nax.scatter(X_demo[es_nucleo, 0],   X_demo[es_nucleo, 1],\n           c='steelblue', s=120, zorder=5, label=f'N√∫cleo (‚â•{minpts} vecinos en Œµ)')\nax.scatter(X_demo[es_frontera, 0], X_demo[es_frontera, 1],\n           c='orange', s=120, zorder=5, label='Frontera (en vecindad de n√∫cleo)')\nax.scatter(X_demo[es_ruido, 0],    X_demo[es_ruido, 1],\n           c='red', marker='x', s=200, zorder=5, linewidths=2.5,\n           label='Ruido / Outlier')\n\n# Anotaciones\nfor i, (x, y) in enumerate(X_demo):\n    n = n_vecinos[i]\n    ax.annotate(f'{n}v', (x, y),\n                textcoords=\"offset points\", xytext=(6, 6), fontsize=8, alpha=0.7)\n\nax.set_title(f\"Los tres tipos de puntos en DBSCAN\\n(Œµ={eps}, MinPts={minpts},\"\n             f\" 'Nv' = n¬∫ vecinos en radio Œµ)\",\n             fontsize=12, fontweight='bold')\nax.legend(fontsize=10, loc='upper right')\nax.set_xlim(-0.5, 7.5)\nax.set_ylim(0.5, 6.0)\nax.set_xlabel(\"Caracter√≠stica 1\")\nax.set_ylabel(\"Caracter√≠stica 2\")\n\n# Etiqueta Œµ\nax.annotate('', xy=(X_demo[0, 0] + eps, X_demo[0, 1]),\n            xytext=(X_demo[0, 0], X_demo[0, 1]),\n            arrowprops=dict(arrowstyle='<->', color='steelblue', lw=1.5))\nax.text(X_demo[0, 0] + eps/2, X_demo[0, 1] - 0.18, 'Œµ',\n        fontsize=11, color='steelblue', ha='center')\n\nplt.tight_layout()\nplt.savefig(\"img_dbscan_tipos_puntos.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"Puntos n√∫cleo:    {es_nucleo.sum()}\")\nprint(f\"Puntos frontera:  {es_frontera.sum()}\")\nprint(f\"Puntos ruido:     {es_ruido.sum()}\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_7669bb",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Los c√≠rculos azules son los radios Œµ alrededor de algunos puntos n√∫cleo. El n√∫mero anotado junto a cada punto indica cu√°ntos vecinos tiene dentro de ese radio ‚Äîincluy√©ndose a s√≠ mismo. Los puntos azules tienen ‚â• MinPts vecinos: son n√∫cleo. El naranja est√° en la vecindad de un n√∫cleo pero no tiene suficientes vecinos propios: es frontera. Las X rojas no pertenecen a ninguna vecindad densa: son outliers.\"*\n\n*\"N√≥tese que el punto naranja en la posici√≥n (3,2) est√° entre los dos clusters pero tiene muy pocos vecinos ‚Äîno llega a ser n√∫cleo‚Äî y solo est√° en el borde de un cluster. Esta es la zona gris de DBSCAN.\"*\n\n---\n\n#### Celda 3 ‚Äî DBSCAN vs. K-Means en datasets no convexos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_38b35b",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# LA DEMOSTRACI√ìN CLAVE: lo que K-Means no puede hacer\n# -------------------------------------------------------\n\ndatasets = {\n    'Lunas': make_moons(n_samples=300, noise=0.05, random_state=42),\n    'C√≠rculos': make_circles(n_samples=300, noise=0.05, factor=0.5, random_state=42),\n    'Blobs': make_blobs(n_samples=300, centers=3, cluster_std=0.6, random_state=42),\n}\n\nparams_dbscan = {\n    'Lunas':     {'eps': 0.15, 'min_samples': 5},\n    'C√≠rculos':  {'eps': 0.15, 'min_samples': 5},\n    'Blobs':     {'eps': 0.5,  'min_samples': 5},\n}\nk_kmeans = {'Lunas': 2, 'C√≠rculos': 2, 'Blobs': 3}\n\nfig, axes = plt.subplots(3, 3, figsize=(15, 13))\n\nfor row, (nombre, (X, y_real)) in enumerate(datasets.items()):\n    X_norm = StandardScaler().fit_transform(X)\n\n    # Columna 0: datos reales\n    axes[row, 0].scatter(X_norm[:, 0], X_norm[:, 1],\n                         c=y_real, cmap='tab10', s=20, alpha=0.7)\n    axes[row, 0].set_title(f\"{nombre}\\n(etiquetas reales)\", fontsize=10)\n\n    # Columna 1: K-Means\n    km = KMeans(n_clusters=k_kmeans[nombre], n_init=10, random_state=42)\n    labels_km = km.fit_predict(X_norm)\n    axes[row, 1].scatter(X_norm[:, 0], X_norm[:, 1],\n                         c=labels_km, cmap='tab10', s=20, alpha=0.7)\n    axes[row, 1].scatter(km.cluster_centers_[:, 0],\n                         km.cluster_centers_[:, 1],\n                         c='red', marker='X', s=150, zorder=5)\n    axes[row, 1].set_title(f\"K-Means k={k_kmeans[nombre]}\", fontsize=10)\n\n    # Columna 2: DBSCAN\n    p = params_dbscan[nombre]\n    db = DBSCAN(eps=p['eps'], min_samples=p['min_samples'])\n    labels_db = db.fit_predict(X_norm)\n    n_clusters = len(set(labels_db)) - (1 if -1 in labels_db else 0)\n    n_noise    = (labels_db == -1).sum()\n\n    # Outliers con estilo especial\n    mask_noise = labels_db == -1\n    axes[row, 2].scatter(X_norm[~mask_noise, 0], X_norm[~mask_noise, 1],\n                         c=labels_db[~mask_noise], cmap='tab10', s=20, alpha=0.8)\n    axes[row, 2].scatter(X_norm[mask_noise, 0], X_norm[mask_noise, 1],\n                         c='black', marker='x', s=60, linewidths=1.5,\n                         label=f'Ruido ({n_noise})', zorder=5)\n    if n_noise > 0:\n        axes[row, 2].legend(fontsize=8)\n    axes[row, 2].set_title(\n        f\"DBSCAN Œµ={p['eps']} MinPts={p['min_samples']}\\n\"\n        f\"‚Üí {n_clusters} clusters, {n_noise} outliers\", fontsize=10\n    )\n\n# Encabezados de columna\nfor ax, titulo in zip(axes[0], ['Datos reales', 'K-Means', 'DBSCAN']):\n    ax.set_title(titulo + '\\n' + ax.get_title(), fontsize=11, fontweight='bold')\n\nplt.suptitle(\"K-Means vs. DBSCAN en tres morfolog√≠as de datos\",\n             fontsize=14, fontweight='bold', y=1.01)\nplt.tight_layout()\nplt.savefig(\"img_dbscan_vs_kmeans_morfologias.png\", dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "md_b29e5e",
   "metadata": {},
   "source": "**Script de explicaci√≥n ‚Äî momento clave del bloque:**\n\n*\"Esta es la imagen que quiero que os llev√©is grabada. Fila superior: dataset de lunas. K-Means corta por la mitad ambas lunas ‚Äîno puede hacer nada mejor porque los clusters no son esf√©ricos. DBSCAN las identifica perfectamente siguiendo la densidad. Fila media: lo mismo con c√≠rculos conc√©ntricos. K-Means falla completamente. DBSCAN perfecto.\"*\n\n*\"La fila inferior es el dataset de blobs: aqu√≠ los dos algoritmos dan resultados equivalentes porque los clusters S√ç son convexos y esf√©ricos. Cuando los datos encajan con los supuestos de K-Means, ambos funcionan bien. La diferencia solo aparece cuando esos supuestos se violan.\"*\n\n---\n\n#### Celda 4 ‚Äî El gr√°fico k-distancia para elegir Œµ"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_57c591",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# T√©cnica sistem√°tica para elegir Œµ\n# -------------------------------------------------------\n\n# Usamos el dataset de lunas con ruido moderado\nX_lunas, _ = make_moons(n_samples=400, noise=0.08, random_state=42)\nX_lunas_norm = StandardScaler().fit_transform(X_lunas)\n\nminpts = 5  # nuestro MinPts elegido\n\n# Calculamos la distancia al k-√©simo vecino m√°s cercano (k = MinPts - 1)\nnbrs = NearestNeighbors(n_neighbors=minpts).fit(X_lunas_norm)\ndistancias, _ = nbrs.kneighbors(X_lunas_norm)\nk_dist = np.sort(distancias[:, -1])[::-1]  # distancia al vecino m√°s lejano, ordenada\n\n# Detectamos el codo autom√°ticamente\n# (m√°xima curvatura en la curva k-distancia)\nfrom numpy.linalg import norm\n\ndef encontrar_codo(y):\n    \"\"\"Detecta el codo de una curva usando el m√©todo de la l√≠nea recta.\"\"\"\n    n = len(y)\n    x = np.arange(n)\n    # Vector desde el primer al √∫ltimo punto\n    inicio = np.array([x[0], y[0]])\n    fin    = np.array([x[-1], y[-1]])\n    linea  = fin - inicio\n    linea_norm = linea / norm(linea)\n    # Distancia perpendicular de cada punto a la l√≠nea\n    dists_perp = np.array([\n        norm(np.cross(linea_norm, np.array([x[i], y[i]]) - inicio))\n        for i in range(n)\n    ])\n    return np.argmax(dists_perp)\n\nidx_codo = encontrar_codo(k_dist)\neps_optimo = k_dist[idx_codo]\n\n# Visualizaci√≥n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Gr√°fico k-distancia\nax1 = axes[0]\nax1.plot(range(len(k_dist)), k_dist, color='steelblue', linewidth=2)\nax1.axhline(y=eps_optimo, color='red', linestyle='--', linewidth=2,\n            label=f'Œµ sugerido = {eps_optimo:.3f}')\nax1.axvline(x=idx_codo, color='orange', linestyle=':', linewidth=2,\n            label=f'Codo en √≠ndice {idx_codo}')\nax1.scatter([idx_codo], [eps_optimo], c='red', s=100, zorder=5)\nax1.set_xlabel(f\"Puntos ordenados por distancia al {minpts}-√©simo vecino\")\nax1.set_ylabel(f\"Distancia al {minpts}-√©simo vecino m√°s cercano\")\nax1.set_title(f\"Gr√°fico k-distancia (MinPts={minpts})\\n‚Üí Œµ ‚âà {eps_optimo:.3f}\",\n              fontsize=11, fontweight='bold')\nax1.legend(fontsize=10)\n\n# Resultado de DBSCAN con Œµ autom√°tico\ndb_auto = DBSCAN(eps=eps_optimo, min_samples=minpts)\nlabels_auto = db_auto.fit_predict(X_lunas_norm)\nn_cls = len(set(labels_auto)) - (1 if -1 in labels_auto else 0)\nn_nse = (labels_auto == -1).sum()\n\nax2 = axes[1]\nmask_noise = labels_auto == -1\nax2.scatter(X_lunas_norm[~mask_noise, 0], X_lunas_norm[~mask_noise, 1],\n            c=labels_auto[~mask_noise], cmap='tab10', s=25, alpha=0.8)\nax2.scatter(X_lunas_norm[mask_noise, 0], X_lunas_norm[mask_noise, 1],\n            c='black', marker='x', s=60, linewidths=1.5,\n            label=f'Ruido: {n_nse} puntos')\nax2.set_title(f\"DBSCAN con Œµ={eps_optimo:.3f}, MinPts={minpts}\\n\"\n              f\"‚Üí {n_cls} clusters, {n_nse} outliers detectados\",\n              fontsize=11, fontweight='bold')\nax2.legend(fontsize=10)\nax2.set_xlabel(\"Caracter√≠stica 1 (norm.)\")\nax2.set_ylabel(\"Caracter√≠stica 2 (norm.)\")\n\nplt.suptitle(\"Selecci√≥n sistem√°tica de Œµ mediante gr√°fico k-distancia\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_dbscan_kdist.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"Œµ sugerido: {eps_optimo:.4f}\")\nprint(f\"Resultado: {n_cls} clusters, {n_nse} outliers\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_baa161",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"El gr√°fico de la izquierda es vuestra br√∫jula para elegir Œµ. El eje X son los puntos ordenados por su distancia al quinto vecino m√°s cercano. Al principio la curva es plana y baja ‚Äîson los puntos n√∫cleo, bien rodeados de vecinos‚Äî. Luego hay un codo donde la curva se dispara hacia arriba: ah√≠ est√°n los puntos frontera y los outliers, que tienen vecinos m√°s lejanos. El Œµ √≥ptimo est√° en ese codo.\"*\n\n*\"La l√≠nea roja marca el Œµ sugerido autom√°ticamente. El resultado de la derecha muestra que con ese Œµ, DBSCAN encuentra correctamente los dos clusters y un pu√±ado de outliers ‚Äîlos puntos que el propio dataset gener√≥ con ruido excesivo.\"*\n\n---\n\n#### Celda 5 ‚Äî Caso pr√°ctico: detecci√≥n de anomal√≠as en e-commerce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_af9801",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# CASO PR√ÅCTICO: Detecci√≥n de comportamiento an√≥malo\n# en transacciones de e-commerce\n# -------------------------------------------------------\n\nnp.random.seed(42)\nn_normal = 400\n\n# Comportamiento normal: correlaci√≥n entre sesiones y compras\nsesiones   = np.random.normal(50, 10, n_normal)\ncompras    = sesiones * 0.3 + np.random.normal(0, 4, n_normal)\nticket_med = np.random.normal(45, 8, n_normal)\n\n# Patrones an√≥malos\n# Tipo 1: muchas sesiones, pocas compras (bots de scraping)\ns_bot  = np.random.uniform(150, 200, 12)\nc_bot  = np.random.uniform(0, 3, 12)\nt_bot  = np.random.uniform(5, 15, 12)\n\n# Tipo 2: pocas sesiones, ticket alt√≠simo (fraude de tarjeta)\ns_frau = np.random.uniform(1, 5, 8)\nc_frau = np.random.uniform(8, 15, 8)\nt_frau = np.random.uniform(300, 500, 8)\n\n# Tipo 3: comportamiento de usuario VIP extremo (leg√≠timo pero outlier)\ns_vip  = np.random.uniform(80, 100, 5)\nc_vip  = np.random.uniform(40, 55, 5)\nt_vip  = np.random.uniform(200, 280, 5)\n\n# Combinamos\nsesiones_all = np.concatenate([sesiones,   s_bot,  s_frau, s_vip])\ncompras_all  = np.concatenate([compras,    c_bot,  c_frau, c_vip])\nticket_all   = np.concatenate([ticket_med, t_bot,  t_frau, t_vip])\ntipo_real    = np.concatenate([\n    ['Normal'] * n_normal,\n    ['Bot (scraping)'] * 12,\n    ['Fraude tarjeta'] * 8,\n    ['VIP extremo'] * 5\n])\n\ndf_ecom = pd.DataFrame({\n    'sesiones_mes':  sesiones_all,\n    'compras_mes':   compras_all,\n    'ticket_medio':  ticket_all,\n    'tipo_real':     tipo_real\n})\n\nprint(f\"Dataset: {len(df_ecom)} usuarios\")\nprint(df_ecom['tipo_real'].value_counts())"
  },
  {
   "cell_type": "markdown",
   "id": "md_8472bc",
   "metadata": {},
   "source": "---\n\n#### Celda 6 ‚Äî Aplicar DBSCAN y visualizar anomal√≠as detectadas"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_69b0e3",
   "metadata": {},
   "outputs": [],
   "source": "# Escalamos y aplicamos DBSCAN\nfeatures = ['sesiones_mes', 'compras_mes', 'ticket_medio']\nscaler_ecom = StandardScaler()\nX_ecom = scaler_ecom.fit_transform(df_ecom[features])\n\n# Elegimos par√°metros con el gr√°fico k-distancia\nnbrs_ecom = NearestNeighbors(n_neighbors=5).fit(X_ecom)\ndist_ecom, _ = nbrs_ecom.kneighbors(X_ecom)\nk_dist_ecom  = np.sort(dist_ecom[:, -1])[::-1]\neps_ecom     = k_dist_ecom[encontrar_codo(k_dist_ecom)]\n\ndb_ecom = DBSCAN(eps=eps_ecom, min_samples=5)\ndf_ecom['cluster_dbscan'] = db_ecom.fit_predict(X_ecom)\n\nn_clusters_ecom = len(set(df_ecom['cluster_dbscan'])) - \\\n                  (1 if -1 in df_ecom['cluster_dbscan'].values else 0)\nn_outliers_ecom = (df_ecom['cluster_dbscan'] == -1).sum()\n\nprint(f\"Œµ utilizado: {eps_ecom:.3f}\")\nprint(f\"Clusters encontrados: {n_clusters_ecom}\")\nprint(f\"Outliers detectados:  {n_outliers_ecom}\")\nprint()\n\n# ¬øQu√© tipo real tienen los outliers detectados?\noutliers_detectados = df_ecom[df_ecom['cluster_dbscan'] == -1]\nprint(\"Composici√≥n de los outliers detectados por DBSCAN:\")\nprint(outliers_detectados['tipo_real'].value_counts())\nprint()\nprint(\"Tasa de detecci√≥n por tipo an√≥malo:\")\nfor tipo in ['Bot (scraping)', 'Fraude tarjeta', 'VIP extremo']:\n    total = (df_ecom['tipo_real'] == tipo).sum()\n    detectados = ((df_ecom['tipo_real'] == tipo) &\n                  (df_ecom['cluster_dbscan'] == -1)).sum()\n    tasa = detectados / total * 100\n    print(f\"  {tipo}: {detectados}/{total} detectados ({tasa:.0f}%)\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_66ae64",
   "metadata": {},
   "source": "---\n\n#### Celda 7 ‚Äî Visualizaci√≥n 3D de los outliers"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_e65d79",
   "metadata": {},
   "outputs": [],
   "source": "from mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(14, 6))\n\n# Vista 2D: Sesiones vs. Ticket Medio\nax1 = fig.add_subplot(121)\ncolores_tipo = {\n    'Normal':        '#377eb8',\n    'Bot (scraping)':'#ff7f00',\n    'Fraude tarjeta':'#e41a1c',\n    'VIP extremo':   '#4daf4a'\n}\n\n# Puntos normales (cluster != -1)\nmask_normal_db = df_ecom['cluster_dbscan'] != -1\nax1.scatter(df_ecom.loc[mask_normal_db, 'sesiones_mes'],\n            df_ecom.loc[mask_normal_db, 'ticket_medio'],\n            c='#377eb8', alpha=0.3, s=20, label='Comportamiento normal')\n\n# Outliers coloreados por tipo real\nfor tipo, color in colores_tipo.items():\n    if tipo == 'Normal':\n        continue\n    mask = (df_ecom['cluster_dbscan'] == -1) & (df_ecom['tipo_real'] == tipo)\n    if mask.sum() > 0:\n        ax1.scatter(df_ecom.loc[mask, 'sesiones_mes'],\n                    df_ecom.loc[mask, 'ticket_medio'],\n                    c=color, s=100, marker='*', zorder=5,\n                    edgecolors='black', linewidths=0.7,\n                    label=f'{tipo} (outlier DBSCAN)')\n\nax1.set_xlabel(\"Sesiones / mes\")\nax1.set_ylabel(\"Ticket medio (‚Ç¨)\")\nax1.set_title(\"Outliers detectados por DBSCAN\\n(coloreados por tipo real)\",\n              fontsize=11, fontweight='bold')\nax1.legend(fontsize=8, loc='upper left')\n\n# Vista 2D: Sesiones vs. Compras\nax2 = fig.add_subplot(122)\nax2.scatter(df_ecom.loc[mask_normal_db, 'sesiones_mes'],\n            df_ecom.loc[mask_normal_db, 'compras_mes'],\n            c='#377eb8', alpha=0.3, s=20, label='Comportamiento normal')\nfor tipo, color in colores_tipo.items():\n    if tipo == 'Normal':\n        continue\n    mask = (df_ecom['cluster_dbscan'] == -1) & (df_ecom['tipo_real'] == tipo)\n    if mask.sum() > 0:\n        ax2.scatter(df_ecom.loc[mask, 'sesiones_mes'],\n                    df_ecom.loc[mask, 'compras_mes'],\n                    c=color, s=100, marker='*', zorder=5,\n                    edgecolors='black', linewidths=0.7,\n                    label=f'{tipo}')\n\nax2.set_xlabel(\"Sesiones / mes\")\nax2.set_ylabel(\"Compras / mes\")\nax2.set_title(\"Vista sesiones vs. compras\\n(mismo coloreado)\",\n              fontsize=11, fontweight='bold')\nax2.legend(fontsize=8)\n\nplt.suptitle(\"DBSCAN como detector de anomal√≠as en e-commerce\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_dbscan_ecommerce_anomalias.png\", dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "md_616102",
   "metadata": {},
   "source": "**Script de interpretaci√≥n del caso pr√°ctico:**\n\n*\"Aqu√≠ est√° la aplicaci√≥n real. Los puntos azules son el comportamiento normal ‚Äîsesiones correlacionadas con compras y ticket medio dentro de rango‚Äî. Las estrellas naranjas son los bots: muchas sesiones, casi ninguna compra ‚Äîun ratio que ning√∫n humano tiene‚Äî. Las estrellas rojas son el fraude: pocas sesiones pero ticket alt√≠simo ‚Äîalguien que entra, compra algo car√≠simo y no vuelve‚Äî. Las verdes son los VIP leg√≠timos pero extremos.\"*\n\n*\"DBSCAN los detecta todos sin que le hayamos dicho qu√© buscar. Solo le dijimos 'encu√©ntrame las regiones densas' y todo lo que no encaja en esas regiones aparece como ruido. En producci√≥n, ese ruido es vuestra lista de casos a revisar por el equipo de fraude.\"*\n\n---\n\n#### Celda 8 ‚Äî Sensibilidad a los par√°metros: an√°lisis de variabilidad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_4bb46b",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# ¬øQu√© pasa si cambiamos Œµ y MinPts?\n# Mapa de calor de resultados\n# -------------------------------------------------------\n\nX_lunas2, _ = make_moons(n_samples=300, noise=0.06, random_state=0)\nX_lunas2_norm = StandardScaler().fit_transform(X_lunas2)\n\neps_vals     = [0.05, 0.10, 0.15, 0.20, 0.30, 0.50]\nminpts_vals  = [3, 5, 8, 12]\n\nresultados_grid = np.zeros((len(minpts_vals), len(eps_vals), 2))  # [clusters, ruido%]\n\nfor i, mp in enumerate(minpts_vals):\n    for j, ep in enumerate(eps_vals):\n        db = DBSCAN(eps=ep, min_samples=mp)\n        lbl = db.fit_predict(X_lunas2_norm)\n        n_cls = len(set(lbl)) - (1 if -1 in lbl else 0)\n        pct_ruido = (lbl == -1).mean() * 100\n        resultados_grid[i, j, 0] = n_cls\n        resultados_grid[i, j, 1] = pct_ruido\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Heatmap: n√∫mero de clusters\nim1 = axes[0].imshow(resultados_grid[:, :, 0], cmap='Blues', aspect='auto')\naxes[0].set_xticks(range(len(eps_vals)))\naxes[0].set_xticklabels([str(e) for e in eps_vals])\naxes[0].set_yticks(range(len(minpts_vals)))\naxes[0].set_yticklabels([str(m) for m in minpts_vals])\naxes[0].set_xlabel(\"Œµ (radio de vecindad)\")\naxes[0].set_ylabel(\"MinPts\")\naxes[0].set_title(\"N√∫mero de clusters\", fontsize=11, fontweight='bold')\nplt.colorbar(im1, ax=axes[0])\nfor i in range(len(minpts_vals)):\n    for j in range(len(eps_vals)):\n        axes[0].text(j, i, int(resultados_grid[i, j, 0]),\n                     ha='center', va='center', fontsize=11, fontweight='bold',\n                     color='white' if resultados_grid[i, j, 0] > 5 else 'black')\n\n# Heatmap: % de ruido\nim2 = axes[1].imshow(resultados_grid[:, :, 1], cmap='Reds', aspect='auto')\naxes[1].set_xticks(range(len(eps_vals)))\naxes[1].set_xticklabels([str(e) for e in eps_vals])\naxes[1].set_yticks(range(len(minpts_vals)))\naxes[1].set_yticklabels([str(m) for m in minpts_vals])\naxes[1].set_xlabel(\"Œµ (radio de vecindad)\")\naxes[1].set_ylabel(\"MinPts\")\naxes[1].set_title(\"% de puntos clasificados como ruido\", fontsize=11, fontweight='bold')\nplt.colorbar(im2, ax=axes[1], label=\"%\")\nfor i in range(len(minpts_vals)):\n    for j in range(len(eps_vals)):\n        axes[1].text(j, i, f\"{resultados_grid[i, j, 1]:.0f}%\",\n                     ha='center', va='center', fontsize=10, fontweight='bold',\n                     color='white' if resultados_grid[i, j, 1] > 40 else 'black')\n\nplt.suptitle(\"Sensibilidad de DBSCAN a los hiperpar√°metros ‚Äî Dataset 'Lunas'\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_dbscan_sensibilidad.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"Interpretaci√≥n:\")\nprint(\"  Œµ peque√±o + MinPts alto  ‚Üí muchos clusters peque√±os, alto % ruido\")\nprint(\"  Œµ grande + MinPts bajo   ‚Üí pocos clusters grandes, bajo % ruido (o 1 cluster)\")\nprint(\"  Zona intermedia          ‚Üí resultado √∫til (2 clusters, ~5-15% ruido)\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_537775",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Este mapa de calor os permite ver de un vistazo c√≥mo cambia el comportamiento de DBSCAN al variar sus par√°metros. Con Œµ muy peque√±o ‚Äîcolumna izquierda‚Äî casi todo es ruido porque los radios son demasiado peque√±os. Con Œµ muy grande ‚Äîcolumna derecha‚Äî todo se fusiona en un √∫nico cluster enorme. La zona √∫til para este dataset est√° en el centro: Œµ entre 0.10 y 0.20, MinPts entre 3 y 8.\"*\n\n*\"Usad este tipo de an√°lisis de sensibilidad cuando no est√©is seguros de vuestros par√°metros. Especialmente si vuestros datos tienen ruido variable o densidad no uniforme.\"*\n\n---\n\n#### Celda 9 ‚Äî Menci√≥n a HDBSCAN"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_a6bbe5",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# HDBSCAN: la evoluci√≥n natural de DBSCAN\n# (Demo r√°pida, sin profundizar)\n# -------------------------------------------------------\n\ntry:\n    import hdbscan\n\n    # Dataset con clusters de densidad variable\n    np.random.seed(5)\n    X_var = np.vstack([\n        np.random.normal([0, 0], [0.3, 0.3], (150,)),   # cluster denso\n        np.random.normal([4, 4], [1.2, 1.2], (150,)),   # cluster disperso\n        np.random.normal([8, 0], [0.4, 0.4], (100,)),   # cluster denso\n        np.random.uniform(-3, 11, (20, 2))               # ruido uniforme\n    ])\n    X_var_norm = StandardScaler().fit_transform(X_var)\n\n    # DBSCAN cl√°sico (dif√≠cil calibrar para densidades distintas)\n    db_var = DBSCAN(eps=0.35, min_samples=5).fit_predict(X_var_norm)\n\n    # HDBSCAN (sin necesidad de Œµ)\n    hdb = hdbscan.HDBSCAN(min_cluster_size=15, min_samples=5)\n    labels_hdb = hdb.fit_predict(X_var_norm)\n\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n\n    for ax, labels, titulo in zip(\n        axes,\n        [np.arange(len(X_var)) // (len(X_var)//3),  # grupos reales aprox.\n         db_var, labels_hdb],\n        ['Datos (grupos aproximados)', f'DBSCAN Œµ=0.35', 'HDBSCAN (sin Œµ)']\n    ):\n        mask_noise = labels == -1\n        if mask_noise.sum() > 0:\n            ax.scatter(X_var_norm[mask_noise, 0], X_var_norm[mask_noise, 1],\n                       c='black', marker='x', s=40, alpha=0.5)\n        ax.scatter(X_var_norm[~mask_noise, 0], X_var_norm[~mask_noise, 1],\n                   c=labels[~mask_noise], cmap='tab10', s=25, alpha=0.8)\n        n_c = len(set(labels)) - (1 if -1 in labels else 0)\n        n_n = mask_noise.sum()\n        ax.set_title(f\"{titulo}\\n{n_c} clusters, {n_n} outliers\",\n                     fontsize=10, fontweight='bold')\n\n    plt.suptitle(\"Densidades variables: DBSCAN vs. HDBSCAN\",\n                 fontsize=12, fontweight='bold')\n    plt.tight_layout()\n    plt.savefig(\"img_hdbscan_vs_dbscan.png\", dpi=150, bbox_inches='tight')\n    plt.show()\n\n    print(\"HDBSCAN disponible. Instalaci√≥n: pip install hdbscan\")\n\nexcept ImportError:\n    print(\"HDBSCAN no instalado. Ejecutar: pip install hdbscan\")\n    print(\"Concepto clave: HDBSCAN elimina la necesidad de Œµ construyendo\")\n    print(\"una jerarqu√≠a de densidad y extrayendo los clusters m√°s estables.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_907b4d",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"HDBSCAN es la evoluci√≥n directa de DBSCAN. El problema de DBSCAN con densidades variables es real: si un dataset tiene un cluster muy denso junto a uno m√°s disperso, un √∫nico Œµ no puede capturar bien los dos. HDBSCAN construye internamente una jerarqu√≠a de densidades ‚Äîcomo un dendrograma del clustering jer√°rquico pero basado en densidad‚Äî y extrae los clusters m√°s estables en esa jerarqu√≠a. Solo necesita `min_cluster_size`. En datasets reales con estructura irregular, HDBSCAN suele superar a DBSCAN.\"*\n\n---\n\n#### Celda 10 ‚Äî Resumen comparativo de los cuatro algoritmos de la Sesi√≥n 1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_df21f0",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 65)\nprint(\"TABLA COMPARATIVA FINAL ‚Äî SESI√ìN 1\")\nprint(\"=\" * 65)\n\ntabla = pd.DataFrame({\n    'K-Means': {\n        'Tipo':             'Particional',\n        'Especifica k':     'S√≠ (obligatorio)',\n        'Forma clusters':   'Esf√©rica',\n        'Outliers':         'Sensible',\n        'Representante':    'Centroide (ficticio)',\n        'Escalabilidad':    'Excelente (O(n¬∑k¬∑d))',\n        'Mejor para':       'n grande, clusters bien separados',\n    },\n    'K-Medoids': {\n        'Tipo':             'Particional',\n        'Especifica k':     'S√≠ (obligatorio)',\n        'Forma clusters':   'Esf√©rica',\n        'Outliers':         'Robusto',\n        'Representante':    'Medoide (punto real)',\n        'Escalabilidad':    'Limitada (O(k(n-k)¬≤))',\n        'Mejor para':       'Outliers presentes, representantes reales',\n    },\n    'Jer√°rquico': {\n        'Tipo':             'Jer√°rquico',\n        'Especifica k':     'No (corte flexible)',\n        'Forma clusters':   'Depende del enlace',\n        'Outliers':         'Moderado',\n        'Representante':    'Ninguno (√°rbol)',\n        'Escalabilidad':    'Pobre (O(n¬≤))',\n        'Mejor para':       'Exploraci√≥n, n peque√±o, estructura anidada',\n    },\n    'DBSCAN': {\n        'Tipo':             'Densidad',\n        'Especifica k':     'No (emerge de datos)',\n        'Forma clusters':   'Arbitraria',\n        'Outliers':         'Nativo',\n        'Representante':    'Ninguno',\n        'Escalabilidad':    'Buena (O(n log n))',\n        'Mejor para':       'Formas arbitrarias, detecci√≥n de anomal√≠as',\n    },\n}).T\n\nprint(tabla.to_string())\nprint()\nprint(\"Regla de selecci√≥n r√°pida:\")\nprint(\"  ¬øForma arbitraria o necesito detectar outliers?    ‚Üí DBSCAN\")\nprint(\"  ¬øQuiero explorar k sin decidirlo a priori?         ‚Üí Jer√°rquico\")\nprint(\"  ¬øHay outliers y necesito representantes reales?    ‚Üí K-Medoids\")\nprint(\"  ¬øDataset grande, datos limpios, k conocido?        ‚Üí K-Means\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_6fe374",
   "metadata": {},
   "source": "---\n\n## NOTAS DE PRODUCCI√ìN\n\n### Para las slides\n\n- **Slide 1:** Portada del bloque. Las tres im√°genes del fracaso de K-Means en lunas y c√≠rculos vs. DBSCAN resolvi√©ndolos.\n- **Slide 2:** Los dos par√°metros Œµ y MinPts con diagrama geom√©trico mostrando la Œµ-vecindad.\n- **Slide 3:** Los tres tipos de puntos ‚Äî diagrama con puntos coloreados, c√≠rculos Œµ y etiquetas.\n- **Slide 4:** Pseudoc√≥digo del algoritmo con la met√°fora de la epidemia.\n- **Slide 5:** T√©cnica k-distancia ‚Äî gr√°fico con el codo se√±alado.\n- **Slide 6:** Tabla resumen de DBSCAN vs. los tres algoritmos anteriores.\n- **Slide 7:** Tarjeta de presentaci√≥n de HDBSCAN ‚Äî cu√°ndo y por qu√© usarlo.\n\n### Para el handout\n\n- Tabla comparativa de los 4 algoritmos (criterios de selecci√≥n).\n- Diagrama de los 3 tipos de puntos (Celda 2).\n- Gr√°fico comparativo K-Means vs. DBSCAN en las tres morfolog√≠as (Celda 3).\n- Gu√≠a para elegir Œµ: pasos del gr√°fico k-distancia.\n- Mapa de calor de sensibilidad a par√°metros (Celda 8).\n- Checklist de decisi√≥n: *¬øForma arbitraria? ‚Üí DBSCAN. ¬øDensidades variables? ‚Üí HDBSCAN.*\n\n### Para el Jupyter Notebook (ejercicios a completar por los alumnos)\n\n**Ejercicio 1 (Celda 4 ampliada):** Repetir el an√°lisis del gr√°fico k-distancia con MinPts = 3, 5, 8 y 12. ¬øEl Œµ sugerido cambia mucho? ¬øCu√°l produce el mejor resultado visual?\n\n**Ejercicio 2 (Celda 6 ampliada):** Modificar el dataset de e-commerce a√±adiendo un nuevo tipo de anomal√≠a: usuarios con exactamente 1 sesi√≥n y 1 compra con ticket muy alto (posible compra impulsiva de producto caro). ¬øDBSCAN los detecta como outliers o los incluye en el cluster normal?\n\n**Ejercicio 3 (Celda 8 ampliada):** A√±adir al mapa de calor una tercera m√©trica: el Silhouette Score (solo para los puntos no-ruido). ¬øLos par√°metros con mejor Silhouette coinciden con los que producen el resultado visual m√°s limpio?\n\n**Ejercicio 4 (avanzado):** Implementar el algoritmo DBSCAN desde cero usando solo NumPy. El resultado debe coincidir con `sklearn.cluster.DBSCAN` en asignaciones de n√∫cleo/frontera/ruido. Verificar con `adjusted_rand_score`.\n\n---\n\n## GESTI√ìN DEL TIEMPO\n\n| Segmento | Duraci√≥n | Indicador de progreso |\n|---|---|---|\n| Transici√≥n y motivaci√≥n visual | 4 min | Las tres im√°genes de fallo de K-Means en pantalla |\n| Los tres tipos de puntos + dos par√°metros | 9 min | Diagrama geom√©trico en pantalla |\n| El algoritmo y la met√°fora de la epidemia | 5 min | Pseudoc√≥digo en pantalla |\n| Gr√°fico k-distancia para elegir Œµ | 4 min | Gr√°fico anotado en pantalla |\n| Posicionamiento vs. algoritmos anteriores | 3 min | Tabla comparativa en pantalla |\n| Celda 1-2 (imports + tipos de puntos) | 8 min | Diagrama generado |\n| Celda 3 (K-Means vs. DBSCAN morfolog√≠as) | 8 min | Los 9 subplots generados |\n| Celda 4 (k-distancia) | 6 min | Gr√°fico de codo generado |\n| Celda 5-7 (caso e-commerce) | 8 min | Tasas de detecci√≥n impresas |\n| Celda 8 (sensibilidad par√°metros) | 5 min | Mapa de calor generado |\n| Celda 9-10 (HDBSCAN + tabla final) | 3 min | Tabla comparativa impresa |\n| Discusi√≥n de cierre | 3 min buffer | ‚Äî |\n| **Total** | **66 min** *(+6 min de margen)* | |\n\n> *Nota: Si el tiempo aprieta, la Celda 9 (HDBSCAN) es prescindible y puede quedar como lectura opcional. La Celda 10 (tabla comparativa) es cr√≠tica ‚Äî no omitir porque conecta con la recapitulaci√≥n final de la Sesi√≥n 1.*\n\n---\n\n*Bloque 1.4 desarrollado para el m√≥dulo \"Algoritmos de Clustering\" ‚Äî M√°ster en Ciencia de Datos*"
  },
  {
   "cell_type": "markdown",
   "id": "md_61368b",
   "metadata": {},
   "source": "---\n## üí° Para explorar m√°s ‚Äî Ejercicios propuestos\n\nLos ejercicios pr√°cticos est√°n marcados con comentarios `# EJERCICIO` en el c√≥digo.\n\n**Entrega sugerida:** Exporta este notebook como HTML o PDF (`File ‚Üí Download ‚Üí HTML`)\ny a√±ade tus conclusiones en una celda Markdown al final de cada secci√≥n.\n\n---\n*M√°ster en Ciencia de Datos ¬∑ M√≥dulo Clustering ¬∑ Bloque 1.4*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}