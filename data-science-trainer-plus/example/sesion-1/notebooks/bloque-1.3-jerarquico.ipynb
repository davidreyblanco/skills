{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_e7436c",
   "metadata": {},
   "source": "# Bloque 1.3 ‚Äî Clustering Jer√°rquico\n**M√°ster en Ciencia de Datos ¬∑ M√≥dulo: Algoritmos de Clustering**\n**Sesi√≥n 1 ¬∑ Duraci√≥n: 65 min**\n\n---\n> üìå **C√≥mo usar este notebook:**\n> Ejecuta las celdas **en orden**. Cada secci√≥n comienza con explicaci√≥n te√≥rica (en Markdown) seguida del c√≥digo correspondiente.\n> Los comentarios `# ---` delimitan ejercicios opcionales para profundizar.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_21e9fd",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# BLOQUE 1.3 ‚Äî Clustering Jer√°rquico\n# ============================================================\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.datasets import make_blobs\nfrom scipy.cluster.hierarchy import dendrogram, linkage, fcluster\nfrom scipy.spatial.distance import pdist\n\nplt.rcParams['figure.figsize'] = (12, 6)\nplt.rcParams['font.size'] = 12\nsns.set_style(\"whitegrid\")\nnp.random.seed(42)\n\nprint(\"‚úì Imports correctos\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_74b419",
   "metadata": {},
   "source": "---\n\n#### Celda 2 ‚Äî Visualizaci√≥n del algoritmo aglomerativo paso a paso (dataset m√≠nimo)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_e47034",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# Demostraci√≥n con un dataset MUY peque√±o (8 puntos)\n# para ver cada fusi√≥n de forma expl√≠cita\n# -------------------------------------------------------\n\n# 8 puntos en 2D con estructura de 3 grupos\nX_mini = np.array([\n    [1.0, 1.0],  # grupo A\n    [1.5, 1.2],\n    [1.2, 0.8],\n    [5.0, 5.0],  # grupo B\n    [5.3, 4.8],\n    [4.8, 5.2],\n    [9.0, 1.0],  # grupo C\n    [9.2, 1.3],\n])\netiquetas_reales = ['A1','A2','A3','B1','B2','B3','C1','C2']\n\n# Calculamos la matriz de linkage con Ward\nZ = linkage(X_mini, method='ward')\n\nprint(\"Historial de fusiones (m√©todo Ward):\")\nprint(f\"{'Paso':>4}  {'Cluster i':>10}  {'Cluster j':>10}  {'Distancia':>10}  {'Tama√±o':>7}\")\nprint(\"-\" * 50)\nn = len(X_mini)\nfor i, (ci, cj, dist, size) in enumerate(Z):\n    label_i = etiquetas_reales[int(ci)] if ci < n else f\"Cluster-{int(ci)-n+1}\"\n    label_j = etiquetas_reales[int(cj)] if cj < n else f\"Cluster-{int(cj)-n+1}\"\n    print(f\"{i+1:>4}  {label_i:>10}  {label_j:>10}  {dist:>10.3f}  {int(size):>7}\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_41393e",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Este es el historial completo de fusiones. En el paso 1 se fusionan los puntos m√°s cercanos ‚Äîprobablemente dos puntos dentro del mismo grupo real. Despu√©s se van formando grupos m√°s grandes. En los √∫ltimos pasos, la distancia da un salto grande: esos son los grupos 'reales' fusion√°ndose forzosamente.\"*\n\n*\"Ahora vamos a visualizar exactamente este historial como dendrograma.\"*\n\n---\n\n#### Celda 3 ‚Äî El dendrograma explicado capa a capa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_494ce6",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# --- Izquierda: los puntos en 2D ---\nax = axes[0]\ncolores_reales = ['#e41a1c','#e41a1c','#e41a1c',\n                   '#377eb8','#377eb8','#377eb8',\n                   '#4daf4a','#4daf4a']\nfor i, (x, y) in enumerate(X_mini):\n    ax.scatter(x, y, c=colores_reales[i], s=150, zorder=5)\n    ax.annotate(etiquetas_reales[i], (x, y),\n                textcoords=\"offset points\", xytext=(8, 5), fontsize=11)\nax.set_title(\"Puntos en el espacio original\", fontsize=12, fontweight='bold')\nax.set_xlabel(\"Caracter√≠stica 1\")\nax.set_ylabel(\"Caracter√≠stica 2\")\nax.set_xlim(-0.5, 11)\nax.set_ylim(-0.5, 7)\n\n# --- Derecha: el dendrograma ---\nax2 = axes[1]\ndendrogram(\n    Z,\n    labels=etiquetas_reales,\n    ax=ax2,\n    color_threshold=4.0,    # umbral visual para colorear ramas\n    leaf_font_size=11,\n    above_threshold_color='gray'\n)\nax2.set_title(\"Dendrograma (m√©todo Ward)\", fontsize=12, fontweight='bold')\nax2.set_xlabel(\"Puntos\")\nax2.set_ylabel(\"Distancia de fusi√≥n (Ward)\")\n\n# L√≠nea de corte sugerida\nax2.axhline(y=4.0, color='red', linestyle='--', linewidth=2,\n            label='Corte ‚Üí 3 clusters')\nax2.legend(fontsize=10)\n\nplt.suptitle(\"Del espacio 2D al dendrograma ‚Äî lectura directa\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_dendrograma_mini.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"Lectura del dendrograma:\")\nprint(\"  Eje X ‚Üí puntos individuales (hojas del √°rbol)\")\nprint(\"  Eje Y ‚Üí altura de la fusi√≥n (mayor = m√°s distintos al fusionarse)\")\nprint(\"  L√≠nea roja ‚Üí corte que produce k=3 clusters\")\nprint(\"  Grupos formados al cortar: {A1,A2,A3}, {B1,B2,B3}, {C1,C2}\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_301364",
   "metadata": {},
   "source": "**Script de explicaci√≥n del dendrograma:**\n\n*\"Mirad la estructura del √°rbol. Abajo est√°n los puntos individuales. Las ramas que se unen bajas son fusiones de puntos muy cercanos ‚Äîdentro del mismo grupo real. Conforme subimos, vemos c√≥mo se consolidan los grupos. El salto m√°s grande est√° justo antes de que los tres grupos se fusionen en uno. La l√≠nea roja corta el √°rbol en ese punto y nos da tres clusters.\"*\n\n*\"La altura de cada fusi√≥n en el eje Y es vuestra informaci√≥n m√°s valiosa. Un salto grande indica una discontinuidad real en los datos.\"*\n\n---\n\n#### Celda 4 ‚Äî Comparaci√≥n de criterios de enlace"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_93e85d",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# ¬øC√≥mo cambia el dendrograma seg√∫n el criterio de enlace?\n# -------------------------------------------------------\n\n# Dataset con estructura m√°s compleja para ver diferencias\nnp.random.seed(7)\nX_comp, _ = make_blobs(n_samples=80,\n                        centers=[[-4,0],[0,0],[4,0],[0,4]],\n                        cluster_std=[0.5, 0.5, 0.5, 1.5])\n\nmetodos = ['single', 'complete', 'average', 'ward']\ntitulos = [\n    'Single linkage\\n(par m√°s cercano)',\n    'Complete linkage\\n(par m√°s lejano)',\n    'Average linkage\\n(media de pares)',\n    'Ward\\n(m√≠nimo WCSS)'\n]\n\nfig, axes = plt.subplots(1, 4, figsize=(20, 6))\n\nfor ax, metodo, titulo in zip(axes, metodos, titulos):\n    Z_m = linkage(X_comp, method=metodo)\n    dendrogram(Z_m, ax=ax, no_labels=True,\n               color_threshold=0.6 * max(Z_m[:, 2]))\n    ax.set_title(titulo, fontsize=11, fontweight='bold')\n    ax.set_ylabel(\"Distancia de fusi√≥n\")\n    ax.set_xlabel(\"Puntos\")\n\nplt.suptitle(\"Mismo dataset ‚Äî cuatro criterios de enlace, cuatro dendrogramas\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_linkage_comparacion.png\", dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "md_9f3c37",
   "metadata": {},
   "source": "**Script de explicaci√≥n de cada criterio:**\n\n*\"Fij√©monos en Single linkage ‚Äîel primero. La estructura es muy 'plana' en los niveles bajos: muchas fusiones peque√±as antes del gran salto. Este es el efecto cadena: los puntos se van encadenando de uno en uno. Funciona bien para clusters de forma arbitraria pero es muy sensible a outliers.\"*\n\n*\"Complete linkage fuerza clusters m√°s compactos. Aqu√≠ el √°rbol es m√°s 'equilibrado'.\"*\n\n*\"Ward es el que produce los saltos m√°s claros y la estructura m√°s limpia. Si busc√°is un criterio por defecto, Ward es casi siempre el mejor punto de partida.\"*\n\n---\n\n#### Celda 5 ‚Äî C√≥mo leer el codo del dendrograma para elegir k"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_46dc78",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# T√©cnica del \"mayor salto\" para elegir k\n# -------------------------------------------------------\n\nZ_ward = linkage(X_comp, method='ward')\n\n# Las alturas de fusi√≥n en orden (las √∫ltimas n-1 fusiones son las m√°s relevantes)\nalturas = Z_ward[:, 2]\nalturas_ordenadas = np.sort(alturas)[::-1]  # de mayor a menor\n\n# Aceleraciones: diferencia entre fusiones consecutivas\naceleraciones = np.diff(alturas_ordenadas)\nk_sugerido = np.argmax(aceleraciones) + 2  # +2 porque diff reduce en 1 y empezamos en k=2\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Dendrograma con l√≠nea de corte autom√°tica\nax1 = axes[0]\numbral = (alturas_ordenadas[k_sugerido - 2] + alturas_ordenadas[k_sugerido - 1]) / 2\ndendrogram(Z_ward, ax=ax1, no_labels=True,\n           color_threshold=umbral)\nax1.axhline(y=umbral, color='red', linestyle='--', linewidth=2,\n            label=f'Corte autom√°tico ‚Üí k={k_sugerido}')\nax1.set_title(f\"Dendrograma Ward ‚Äî Corte sugerido: k={k_sugerido}\",\n              fontsize=11, fontweight='bold')\nax1.set_ylabel(\"Distancia de fusi√≥n\")\nax1.legend(fontsize=10)\n\n# Gr√°fico de aceleraciones (an√°logo al codo de K-Means)\nax2 = axes[1]\nks = range(2, len(aceleraciones) + 2)\nax2.bar(ks, aceleraciones[:len(ks)], color='steelblue', alpha=0.8)\nax2.axvline(x=k_sugerido, color='red', linestyle='--', linewidth=2,\n            label=f'k sugerido = {k_sugerido}')\nax2.set_xlabel(\"N√∫mero de clusters (k)\")\nax2.set_ylabel(\"Aceleraci√≥n de la distancia de fusi√≥n\")\nax2.set_title(\"Mayor salto ‚Üí k √≥ptimo sugerido\", fontsize=11, fontweight='bold')\nax2.legend(fontsize=10)\n\nplt.suptitle(\"Selecci√≥n autom√°tica de k desde el dendrograma\",\n             fontsize=12, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_dendrograma_corte.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"K sugerido por el criterio del mayor salto: k = {k_sugerido}\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_22068e",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"El gr√°fico de la derecha es el equivalente del 'm√©todo del codo' para clustering jer√°rquico. En lugar de graficar la WCSS, graficamos la aceleraci√≥n de las distancias de fusi√≥n: cu√°nto sube el umbral de un paso al siguiente. La barra m√°s alta indica la mayor discontinuidad ‚Äî ah√≠ est√° el 'corte natural'.\"*\n\n---\n\n#### Celda 6 ‚Äî Caso pr√°ctico: Agrupaci√≥n de pa√≠ses por indicadores econ√≥micos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_a3af66",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# CASO PR√ÅCTICO: Pa√≠ses agrupados por indicadores\n# econ√≥micos (dataset simplificado tipo World Bank)\n# -------------------------------------------------------\n\n# Dataset sint√©tico que replica la estructura de datos reales\n# de indicadores macroecon√≥micos por pa√≠s (escala 0-100 normalizada)\nnp.random.seed(0)\n\npaises_data = {\n    'Pa√≠s': [\n        'Alemania','Francia','Italia','Espa√±a','Pa√≠ses Bajos',\n        'Polonia','Hungr√≠a','Ruman√≠a','Bulgaria','Eslovaquia',\n        'Nigeria','Ghana','Kenia','Sud√°frica','Etiop√≠a',\n        'Brasil','M√©xico','Argentina','Colombia','Chile',\n        'China','India','Indonesia','Vietnam','Tailandia',\n        'EEUU','Canad√°','Australia','Jap√≥n','Corea del Sur'\n    ],\n    'PIB_per_capita_idx': [\n        88,84,74,72,90, 52,48,38,35,50,\n        22,25,28,45,15, 45,40,38,35,50,\n        55,32,38,35,42, 95,92,88,85,80\n    ],\n    'IDH': [\n        93,90,88,88,93, 77,77,74,70,77,\n        52,55,55,68,45, 74,74,79,72,80,\n        74,64,68,68,70, 92,92,92,91,90\n    ],\n    'Gini_inv': [  # invertido: mayor = m√°s equitativo\n        60,59,56,52,55, 54,52,56,58,50,\n        48,50,52,48,62, 42,48,45,48,50,\n        52,60,55,60,56, 58,65,68,70,65\n    ],\n    'Esperanza_vida': [\n        80,82,83,83,82, 77,75,74,72,76,\n        54,60,61,62,64, 73,75,76,73,79,\n        75,68,69,73,75, 79,82,83,84,82\n    ]\n}\n\ndf_paises = pd.DataFrame(paises_data).set_index('Pa√≠s')\nprint(f\"Dataset: {df_paises.shape[0]} pa√≠ses, {df_paises.shape[1]} indicadores\")\nprint(df_paises.head(5))"
  },
  {
   "cell_type": "markdown",
   "id": "md_5656b1",
   "metadata": {},
   "source": "---\n\n#### Celda 7 ‚Äî Dendrograma de pa√≠ses + corte e interpretaci√≥n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_eedec2",
   "metadata": {},
   "outputs": [],
   "source": "# Escalamos los datos\nscaler = StandardScaler()\nX_paises = scaler.fit_transform(df_paises)\n\n# Calculamos el linkage con Ward\nZ_paises = linkage(X_paises, method='ward', metric='euclidean')\n\n# ---- Dendrograma anotado ----\nfig, ax = plt.subplots(figsize=(14, 7))\n\ndend = dendrogram(\n    Z_paises,\n    labels=df_paises.index.tolist(),\n    ax=ax,\n    orientation='top',\n    color_threshold=3.5,\n    leaf_font_size=10,\n    leaf_rotation=45\n)\n\n# L√≠nea de corte para k=4\nax.axhline(y=3.5, color='red', linestyle='--', linewidth=2,\n           label='Corte ‚Üí 4 grupos')\nax.set_title(\"Clustering Jer√°rquico de pa√≠ses ‚Äî Indicadores econ√≥micos (Ward)\",\n             fontsize=13, fontweight='bold')\nax.set_ylabel(\"Distancia Ward (disimilitud)\", fontsize=11)\nax.legend(fontsize=11)\n\nplt.tight_layout()\nplt.savefig(\"img_dendrograma_paises.png\", dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "md_c2d7eb",
   "metadata": {},
   "source": "**Script de explicaci√≥n:**\n\n*\"Este dendrograma ya habla por s√≠ solo. Las hojas del √°rbol son los pa√≠ses. Los que se fusionan en niveles bajos son los m√°s parecidos seg√∫n los cuatro indicadores. Mirad c√≥mo Alemania y Pa√≠ses Bajos se fusionan muy pronto, igual que EEUU, Canad√° y Australia. En cambio, el grupo africano se fusiona con los dem√°s en niveles muy altos, lo que indica una gran diferencia estructural.\"*\n\n*\"La l√≠nea roja corta el √°rbol en cuatro grupos. Pero podr√≠a cortarse en tres o en cinco ‚Äî dependiendo de qu√© granularidad tiene sentido para vuestro an√°lisis.\"*\n\n---\n\n#### Celda 8 ‚Äî Extracci√≥n de clusters y visualizaci√≥n con perfiles"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_0e9b2b",
   "metadata": {},
   "outputs": [],
   "source": "# Extraemos las etiquetas para k=4\nfrom scipy.cluster.hierarchy import fcluster\n\nlabels_paises = fcluster(Z_paises, t=4, criterion='maxclust') - 1  # 0-indexed\ndf_paises['Cluster'] = labels_paises\n\n# ---- Perfil medio de cada cluster ----\nperfil = df_paises.groupby('Cluster')[\n    ['PIB_per_capita_idx','IDH','Gini_inv','Esperanza_vida']\n].mean().round(1)\n\nprint(\"Perfil medio de cada cluster:\")\nprint(perfil)\nprint()\n\n# ---- Lista de pa√≠ses por cluster ----\nfor c in sorted(df_paises['Cluster'].unique()):\n    miembros = df_paises[df_paises['Cluster'] == c].index.tolist()\n    print(f\"Cluster {c}: {', '.join(miembros)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_557137",
   "metadata": {},
   "source": "---\n\n#### Celda 9 ‚Äî Heatmap de perfiles para comunicar resultados"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_9414ff",
   "metadata": {},
   "outputs": [],
   "source": "# El heatmap es una forma muy efectiva de comunicar los clusters\n# a una audiencia no t√©cnica\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 6))\n\n# Heatmap de perfiles medios por cluster\nax1 = axes[0]\nperfil_norm = (perfil - perfil.min()) / (perfil.max() - perfil.min())\nsns.heatmap(perfil_norm, annot=perfil, fmt='.0f',\n            cmap='RdYlGn', ax=ax1,\n            linewidths=0.5, linecolor='white',\n            cbar_kws={'label': 'Nivel relativo (0=m√≠nimo, 1=m√°ximo)'})\nax1.set_title(\"Perfil de cada cluster\\n(valor real anotado, color = nivel relativo)\",\n              fontsize=11, fontweight='bold')\nax1.set_xticklabels(ax1.get_xticklabels(), rotation=25, ha='right')\nax1.set_yticklabels([f'Cluster {c}' for c in perfil.index], rotation=0)\n\n# Scatter: PIB vs IDH coloreado por cluster\nax2 = axes[1]\ncolores_c = ['#e41a1c','#377eb8','#4daf4a','#ff7f00']\nfor c in sorted(df_paises['Cluster'].unique()):\n    mask = df_paises['Cluster'] == c\n    ax2.scatter(\n        df_paises.loc[mask,'PIB_per_capita_idx'],\n        df_paises.loc[mask,'IDH'],\n        c=colores_c[c], s=100, label=f'Cluster {c}', alpha=0.85\n    )\n    for pais in df_paises[mask].index:\n        ax2.annotate(pais,\n                     (df_paises.loc[pais,'PIB_per_capita_idx'],\n                      df_paises.loc[pais,'IDH']),\n                     fontsize=7, alpha=0.8,\n                     textcoords=\"offset points\", xytext=(4, 3))\nax2.set_xlabel(\"PIB per c√°pita (√≠ndice)\", fontsize=11)\nax2.set_ylabel(\"IDH\", fontsize=11)\nax2.set_title(\"Pa√≠ses en el espacio PIB-IDH\\ncoloreados por cluster jer√°rquico\",\n              fontsize=11, fontweight='bold')\nax2.legend(fontsize=9)\n\nplt.suptitle(\"Interpretaci√≥n de los clusters jer√°rquicos de pa√≠ses\",\n             fontsize=13, fontweight='bold')\nplt.tight_layout()\nplt.savefig(\"img_paises_clusters_heatmap.png\", dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "md_927adb",
   "metadata": {},
   "source": "**Script de interpretaci√≥n:**\n\n*\"El heatmap es vuestra herramienta de comunicaci√≥n con negocio. El color verde indica nivel alto, el rojo nivel bajo. Mirad el patr√≥n: un cluster tiene verde en todo ‚Äîlos pa√≠ses desarrollados de alto PIB, IDH y equidad‚Äî. Otro tiene rojo en casi todo ‚Äîlos pa√≠ses de bajo desarrollo‚Äî. Los otros dos son posiciones intermedias diferenciadas.\"*\n\n*\"Notad que este resultado no requiri√≥ especificar k de antemano. Lo descubrimos del propio dendrograma. Esa es la ventaja de la exploraci√≥n jer√°rquica.\"*\n\n---\n\n#### Celda 10 ‚Äî Uso de scikit-learn: AgglomerativeClustering"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_357c6d",
   "metadata": {},
   "outputs": [],
   "source": "# -------------------------------------------------------\n# Interfaz de scikit-learn ‚Äî m√°s integrada con pipelines\n# -------------------------------------------------------\n\nfrom sklearn.cluster import AgglomerativeClustering\n\n# Equivalente al scipy + fcluster anterior, pero con API sklearn\nhc = AgglomerativeClustering(\n    n_clusters=4,\n    linkage='ward',       # 'ward', 'complete', 'average', 'single'\n    metric='euclidean'    # Ward solo funciona con euclidiana\n)\nlabels_sklearn = hc.fit_predict(X_paises)\n\n# Verificar que produce los mismos clusters (pueden tener numeraci√≥n distinta)\nfrom sklearn.metrics import adjusted_rand_score\nari = adjusted_rand_score(labels_paises, labels_sklearn)\nprint(f\"Adjusted Rand Index scipy vs sklearn: {ari:.4f}\")\nprint(\"(1.0 = asignaciones id√©nticas, ajustado por numeraci√≥n)\")\n\n# Para distancias no-euclidianas, usar connectivity o precomputed\n# Ejemplo conceptual (no ejecutar sin un dataset adecuado):\n# hc_coseno = AgglomerativeClustering(\n#     n_clusters=4, linkage='average', metric='cosine'\n# )\nprint(\"\\nNota: Para m√©tricas distintas a euclidiana, usar linkage='average'\")\nprint(\"Ward solo est√° definido para distancia euclidiana.\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_9d7b83",
   "metadata": {},
   "source": "---\n\n#### Celda 11 ‚Äî Comparaci√≥n final: Jer√°rquico vs K-Means en el mismo dataset"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "code_e08f53",
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.cluster import KMeans\n\nkm_paises = KMeans(n_clusters=4, n_init=20, random_state=42)\nlabels_km_paises = km_paises.fit_predict(X_paises)\n\nari_comparacion = adjusted_rand_score(labels_paises, labels_km_paises)\nprint(f\"Coincidencia K-Means vs Jer√°rquico (ARI): {ari_comparacion:.4f}\")\nprint()\n\n# Mostrar diferencias\ndf_comp = pd.DataFrame({\n    'Jer√°rquico (Ward)': labels_paises,\n    'K-Means': labels_km_paises\n}, index=df_paises.index)\n\n# Pa√≠ses donde difieren\ndiferencias = df_comp[df_comp.iloc[:,0] != df_comp.iloc[:,1]]\nif len(diferencias) > 0:\n    print(\"Pa√≠ses con asignaci√≥n diferente entre ambos m√©todos:\")\n    print(diferencias)\nelse:\n    print(\"Ambos m√©todos producen la misma agrupaci√≥n (tras ajuste de numeraci√≥n).\")\n\nprint(\"\"\"\nReflexi√≥n:\n  Si K-Means y Jer√°rquico coinciden ‚Üí la estructura es robusta.\n  Si difieren ‚Üí explorar con el dendrograma para entender por qu√©.\n  El jer√°rquico siempre aporta m√°s informaci√≥n (el √°rbol completo).\n\"\"\")"
  },
  {
   "cell_type": "markdown",
   "id": "md_86a213",
   "metadata": {},
   "source": "**Script de discusi√≥n de cierre:**\n\n*\"En datasets peque√±os como este, K-Means y el clustering jer√°rquico suelen dar resultados muy parecidos si los datos tienen estructura clara. La ventaja del jer√°rquico no est√° en que d√© mejores clusters: est√° en que da un √°rbol, que es informaci√≥n adicional. Pod√©is ver qu√© pa√≠ses est√°n 'a punto de' pertenecer a otro cluster, qu√© nivel de granularidad tiene sentido, y c√≥mo se estructuran las relaciones entre grupos.\"*\n\n---\n\n## NOTAS DE PRODUCCI√ìN\n\n### Para las slides\n\n- **Slide 1:** Portada del bloque. Pregunta ret√≥rica: *\"¬øCu√°ntos clusters tiene este dataset?\"* con un dendrograma como imagen de fondo.\n- **Slide 2:** Bottom-up vs. top-down ‚Äî dos diagramas de √°rbol en espejo. Una flecha sube, otra baja.\n- **Slide 3:** Los 4 pasos del algoritmo aglomerativo en pseudoc√≥digo visual.\n- **Slide 4:** Los 4 criterios de enlace ‚Äî f√≥rmula + diagrama geom√©trico mostrando qu√© distancia mide cada uno en un par de clusters.\n- **Slide 5:** C√≥mo leer un dendrograma ‚Äî diagrama anotado con flechas explicando: hojas, altura de fusi√≥n, c√≥mo cortar.\n- **Slide 6:** Tabla resumen de criterios de enlace.\n- **Slide 7:** Comparaci√≥n de 4 dendrogramas del mismo dataset con distintos criterios de enlace (de la Celda 4).\n- **Slide 8:** Cu√°ndo s√≠ / cu√°ndo no usar jer√°rquico ‚Äî dos columnas con iconos.\n\n### Para el handout\n\n- Tabla de criterios de enlace con f√≥rmulas y caracter√≠sticas.\n- Imagen del dendrograma anotado (Celda 3) con gu√≠a de lectura.\n- Imagen comparativa de los 4 criterios de enlace (Celda 4).\n- Heatmap de perfiles de pa√≠ses (Celda 9) como ejemplo de output interpretable.\n- Tabla de decisi√≥n: Jer√°rquico vs. K-Means vs. K-Medoids.\n\n### Para el Jupyter Notebook (ejercicios a completar por los alumnos)\n\n**Ejercicio 1 (Celda 7 ampliada):** Probar cortes a k=3, k=4 y k=5 sobre el dataset de pa√≠ses. Para cada uno, listar los pa√≠ses de cada cluster e interpretar qu√© agrupaci√≥n tiene m√°s sentido geopol√≠ticamente.\n\n**Ejercicio 2 (Celda 4 ampliada):** A√±adir el criterio de Ward al dataset de lunas (`make_moons`). ¬øQu√© sucede? ¬øEl jer√°rquico puede resolver clusters no convexos con alg√∫n criterio de enlace? (Respuesta esperada: single linkage puede, Ward no.)\n\n**Ejercicio 3 (Celda 10 ampliada):** Repetir el an√°lisis de pa√≠ses usando `metric='cosine'` y `linkage='average'`. ¬øLos grupos cambian? ¬øPor qu√© la similitud coseno podr√≠a tener sentido para comparar perfiles de pa√≠ses?\n\n**Ejercicio 4 (avanzado):** Implementar el algoritmo de Single Linkage desde cero usando solo NumPy y una matriz de distancias. Verificar que produce el mismo historial de fusiones que `scipy.cluster.hierarchy.linkage(method='single')`.\n\n---\n\n## GESTI√ìN DEL TIEMPO\n\n| Segmento | Duraci√≥n | Indicador de progreso |\n|---|---|---|\n| Transici√≥n y motivaci√≥n | 4 min | Pregunta de enganche respondida |\n| Aglomerativo vs. divisivo | 6 min | Diagrama en pantalla |\n| Algoritmo y criterios de enlace | 8 min | Tabla de criterios en pantalla |\n| Dendrograma: lectura e interpretaci√≥n | 7 min | Dendrograma anotado en pantalla |\n| Celda 1-2 (imports + pasos manuales) | 8 min | Tabla de fusiones en pantalla |\n| Celda 3 (dendrograma mini) | 7 min | Dendrograma generado e interpretado |\n| Celda 4-5 (comparaci√≥n criterios + corte) | 10 min | Los 4 dendrogramas comparados |\n| Celda 6-9 (caso pa√≠ses) | 12 min | Heatmap de perfiles generado |\n| Celda 10-11 (sklearn + comparaci√≥n K-Means) | 3 min | ARI calculado |\n| Discusi√≥n de cierre | 3 min + 2 buffer | Pregunta respondida |\n| **Total** | **65 min** | |\n\n---\n\n*Bloque 1.3 desarrollado para el m√≥dulo \"Algoritmos de Clustering\" ‚Äî M√°ster en Ciencia de Datos*"
  },
  {
   "cell_type": "markdown",
   "id": "md_f17f7f",
   "metadata": {},
   "source": "---\n## üí° Para explorar m√°s ‚Äî Ejercicios propuestos\n\nLos ejercicios pr√°cticos est√°n marcados con comentarios `# EJERCICIO` en el c√≥digo.\n\n**Entrega sugerida:** Exporta este notebook como HTML o PDF (`File ‚Üí Download ‚Üí HTML`)\ny a√±ade tus conclusiones en una celda Markdown al final de cada secci√≥n.\n\n---\n*M√°ster en Ciencia de Datos ¬∑ M√≥dulo Clustering ¬∑ Bloque 1.3*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}